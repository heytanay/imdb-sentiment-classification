{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104f624-b6cf-41bc-9301-1091789d6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd8c82-59ed-4a19-930e-f54987468e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 5\n",
    "LR = 1e-5\n",
    "MAX_LEN = 64\n",
    "TRAIN_BS = 2\n",
    "VALID_BS = 2\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "FILE_NAME = '../data/IMDB Dataset.csv'\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_MODEL, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e22a6d-b5d4-4d05-b547-2f3a23849f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, review, target):\n",
    "        self.review = review\n",
    "        self.target = target\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.review)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.review[idx])\n",
    "        review = ' '.join(review.split())\n",
    "        \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "        \n",
    "        ids = torch.tensor(inputs['inputs_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
    "        targets = torch.tensor(self.target['idx'], dtype=torch.float)\n",
    "        \n",
    "        return {\n",
    "            'ids': ids,\n",
    "            'mask': mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'targets': targets\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ad8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to train the model\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        optimizer, \n",
    "        scheduler, \n",
    "        train_dataloader, \n",
    "        valid_dataloader\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.train_data = train_dataloader\n",
    "        self.valid_data = valid_dataloader\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def train_one_epoch(self):\n",
    "        prog_bar = tqdm(self.train_data, total=len(self.train_data))\n",
    "        self.model.train()\n",
    "        for idx, inputs in prog_bar:\n",
    "            ids = inputs['ids'].to(device, dtype=torch.long)\n",
    "            mask = inputs['mask'].to(device, dtype=torch.long)\n",
    "            ttis = inputs['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = inputs['targets'].to(device, dtype=torch.float)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(ids=ids, mask=mask, token_type_ids=ttis)\n",
    "            \n",
    "            loss = self.loss_fn(outputs, targets)\n",
    "            prog_bar.set_description('loss: {}'.format())\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "    \n",
    "    def valid_one_epoch(self):\n",
    "        prog_bar = tqdm(self.valid_data, total=len(self.valid_data))\n",
    "        self.model.eval()\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "        for idx, inputs in prog_bar:\n",
    "            ids = inputs['ids'].to(device, dtype=torch.long)\n",
    "            mask = inputs['mask'].to(device, dtype=torch.long)\n",
    "            ttis = inputs['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = inputs['targets'].to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = self.model(ids=ids, mask=mask, token_type_ids=ttis)\n",
    "\n",
    "            all_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            all_predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "        \n",
    "        output_for_accuracy = all_predictions >= 0.5\n",
    "        val_accuracy = accuracy_score(all_targets, output_for_accuracy)\n",
    "        print('Validation Accuracy: {:.2f}'.format(val_accuracy))\n",
    "        \n",
    "        return val_accuracy\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef95bb-d57b-4f4d-959e-cee67c138577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(BERT_MODEL)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, out = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        out = self.drop(out)\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b612f1-54a2-4788-8ac0-bd7d9a1d78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Code\n",
    "if __name__ == '__main__':\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\".format(torch.cuda.get_device_name()))\n",
    "        DEVICE = torch.device('cuda:0')\n",
    "    else:\n",
    "        print(\"[INFO] GPU not found. Using CPU: {}\".format(platform.processor()))\n",
    "        DEVICE = torch.device('cpu')\n",
    "    \n",
    "    data = pd.read_csv(FILE_NAME)\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "    \n",
    "    train_data = data[:45000].sample(frac=1).reset_index(drop=True)\n",
    "    valid_data = data[45000:].sample(frac=1).reset_index(drop=True)\n",
    "    print(f\"[INFO] Training on: {train_data.shape[0]} samples\")\n",
    "    print(f\"[INFO] Validation on: {valid_data.shape[0]} samples\")\n",
    "    \n",
    "    train_set = BERTDataset(\n",
    "        review = train_data['review'].values,\n",
    "        target = train_data['sentiment'].values\n",
    "    )\n",
    "    \n",
    "    valid_set = BERTDataset(\n",
    "        review = valid_data['review'].values,\n",
    "        target = valid_data['sentiment'].values\n",
    "    )\n",
    "    \n",
    "    train = DataLoader(\n",
    "        train_set,\n",
    "        batch_size = TRAIN_BS,\n",
    "        shuffle = True,\n",
    "        num_workers = 4\n",
    "    )\n",
    "    \n",
    "    valid = DataLoader(\n",
    "        valid_set,\n",
    "        batch_size = VALID_BS,\n",
    "        shuffle = False,\n",
    "        num_workers = 2\n",
    "    )\n",
    "    \n",
    "    print(\"[INFO] Created Dataloaders!\")\n",
    "    \n",
    "    model = BERTModel().to(DEVICE)\n",
    "    nb_train_steps = int(len(train_data) / TRAIN_BS * NB_EPOCHS)\n",
    "    optimizer = transformers.AdamW(model.parameters(), lr=LR)\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=nb_train_steps\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(model, optimizer, scheduler, train, valid)\n",
    "    print(\"[INFO] Initialized Trainer and Models, Starting training...\")\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    for epoch in range(1, NB_EPOCHS+1):\n",
    "        print(f\"{'='*20} EPOCH: {epoch} {'='*20}\")\n",
    "        \n",
    "        # Train for 1 epoch\n",
    "        trainer.train_one_epoch()\n",
    "        \n",
    "        # Validate for 1 epoch\n",
    "        current_accuracy = trainer.valid_one_epoch()\n",
    "        \n",
    "        if current_accuracy > best_accuracy:\n",
    "            print(f\"Saving the Model for Best Accuracy: {current_accuracy:.4f} %\")\n",
    "            torch.save(trainer.get_model().state_dict(), \"BERT_BASE_UNCASED_MODEL.pt\")\n",
    "            best_accuracy = current_accuracy\n",
    "    print(\"Model Finished Training!\")\n",
    "    print(f\"Best Accuracy was: {best_accuracy:.4f}%\")\n",
    "    print(f\"Final Accuracy was: {current_accuracy:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fe36a-34be-4321-bc49-8acdfa098b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
